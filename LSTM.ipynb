{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Erc2A41DMzku"
   },
   "source": [
    "# Введение в глубинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 2. Рекуррентные Нейронные Сети\n",
    "\n",
    "## Общая информация\n",
    "Дата выдачи: 20.02.2021\n",
    "\n",
    "Мягкий дедлайн: 15.03.2021 23:59 MSK\n",
    "\n",
    "Жёсткий дедлайн: 18.03.2021 00:59 MSK\n",
    "\n",
    "## Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Система оценивания работы находится в конце этого ноутбука.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "\n",
    "## Формат сдачи\n",
    "Задания сдаются семинаристу на почту. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-02-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия на латинице\n",
    "\n",
    "Тема письма: #группы ДЗ2 ФИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OO3ESLgHDztU"
   },
   "source": [
    "### Ссылка на соревнование Kaggle и данные: https://www.kaggle.com/c/nlp-intro-to-dl-2021/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqWw3aP7wgOL"
   },
   "source": [
    "## 0. Подготовка данных\n",
    "\n",
    "Данные представляют собой корпус текстов с 4-мя категориями. Ваша задача - написать классификатор для этих данных, определяющий, к какой из категорий относится текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T16:33:05.462367Z",
     "start_time": "2021-01-28T16:33:05.025062Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "o031RfNCWTvg",
    "outputId": "d485b272-11da-4589-aa33-8f811aecceb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Российская сборная лидирует по итогам командно...</td>\n",
       "      <td>mchsgov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#СоветМЧС #МЧС #МЧСРОССИИ</td>\n",
       "      <td>mchsgov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Инспекторы ГИБДД Москвы приняли участие во Все...</td>\n",
       "      <td>mospolice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В Главную Военно-Морскую Базу БФ в г.Балтийск ...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Обвиняемые в хищении денежных средств у 32 пож...</td>\n",
       "      <td>mospolice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     source\n",
       "0  Российская сборная лидирует по итогам командно...    mchsgov\n",
       "1                          #СоветМЧС #МЧС #МЧСРОССИИ    mchsgov\n",
       "2  Инспекторы ГИБДД Москвы приняли участие во Все...  mospolice\n",
       "3  В Главную Военно-Морскую Базу БФ в г.Балтийск ...        mil\n",
       "4  Обвиняемые в хищении денежных средств у 32 пож...  mospolice"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"./train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "uRDPCbawWmXo",
    "outputId": "4ecac919-ec37-4a1c-9c21-451b0325ec85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>На полигоне «Погоново» Воронежской области про...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#БудниМЧС #МЧС #МЧСРОССИИ &lt;br&gt;&lt;br&gt;Пожарные тра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Друзья, напоминаем вам, что завтра единый день...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Настольная игра: \"Королевская почта\"&lt;br&gt;&lt;br&gt;По...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Миллиарды писем разносят по почтовым ящикам на...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  На полигоне «Погоново» Воронежской области про...\n",
       "1  #БудниМЧС #МЧС #МЧСРОССИИ <br><br>Пожарные тра...\n",
       "2  Друзья, напоминаем вам, что завтра единый день...\n",
       "3  Настольная игра: \"Королевская почта\"<br><br>По...\n",
       "4  Миллиарды писем разносят по почтовым ящикам на..."
      ]
     },
     "execution_count": 156,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bx2PZCCkQu91"
   },
   "source": [
    "## 1. Предобработка данных (1 балл)\n",
    "\n",
    "В этом задании вам предстоит провести предобработку данных. Баллы ставятся следующим образом:\n",
    "\n",
    "* Привести все тексты к одной длине, заменить слова/токены на числа, факторизовать целевую переменную и т.д.\n",
    "\n",
    "* Использовать токенизатор, который разбил бы все слова на токены (подробнее https://github.com/huggingface/tokenizers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uqD1nJyB_VbL"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x8jQMkjBlnfb",
    "outputId": "77fd373a-53e4-487c-9a89-1ca546aa268b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=300, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer(max_features=300)\n",
    "v.fit(pd.concat([df_train[\"text\"], df_test[\"text\"]]).values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "_eDay_O-M2pf"
   },
   "outputs": [],
   "source": [
    "labeling = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "98r6N1Y2XA8q"
   },
   "outputs": [],
   "source": [
    "X = v.transform(df_train[\"text\"].values.astype('U')).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "t7kKgkuSXOBI"
   },
   "outputs": [],
   "source": [
    "X_global = v.transform(df_test[\"text\"].values.astype('U')).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNCjMp7Y--98",
    "outputId": "87628412-d152-4d32-bf7a-365566d0e5ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mchsgov        2575\n",
       "mil            2575\n",
       "mospolice      2474\n",
       "russianpost    2257\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uhYa-8Sm_n5U"
   },
   "outputs": [],
   "source": [
    "labeling = LabelEncoder()\n",
    "y = labeling.fit_transform(df_train[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-XmxjpiwgOV"
   },
   "source": [
    "## 2. LSTM-сеть (4 балла)\n",
    "\n",
    "В этом задании вам предстоит написать LSTM сеть __вручную__ (то есть без использования стандартных реализаций из keras / torch / tensorflow). Сама архитектура отлично расписана здесь: https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-I8RHUsChulI",
    "outputId": "6556ae17-61bb-4752-ff4c-512b9e2e3847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.2.0+cu92\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (663.1MB)\n",
      "\u001b[K     |████████████████████████████████| 663.1MB 28kB/s \n",
      "\u001b[?25hCollecting torchvision==0.4.0+cu92\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (8.8MB)\n",
      "\u001b[K     |████████████████████████████████| 8.8MB 23.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.2.0+cu92) (1.19.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (1.15.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (7.0.0)\n",
      "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.2.0+cu92 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch, torchvision\n",
      "  Found existing installation: torch 1.8.0+cu101\n",
      "    Uninstalling torch-1.8.0+cu101:\n",
      "      Successfully uninstalled torch-1.8.0+cu101\n",
      "  Found existing installation: torchvision 0.9.0+cu101\n",
      "    Uninstalling torchvision-0.9.0+cu101:\n",
      "      Successfully uninstalled torchvision-0.9.0+cu101\n",
      "Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gnE94sukJiq_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "r0a81YTocWlX"
   },
   "outputs": [],
   "source": [
    "class LSTM_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # Base parameters\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Forget gate layer\n",
    "        self.W_f = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_f = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # Input gate layer\n",
    "        self.W_i = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_i = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_i = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # Candidate values for a cell\n",
    "        self.W_c = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_c = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_c = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # Output gate layer\n",
    "        self.W_o = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_o = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        self.initial_weights()\n",
    "\n",
    "    def initial_weights(self):\n",
    "        std = 1 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x, initial_states=None):\n",
    "        batch_size, total_cells, _ = x.size()\n",
    "        hidden_sequence = []\n",
    "\n",
    "        if initial_states is None:\n",
    "            h_t, c_t = (\n",
    "                torch.zeros(batch_size, self.hidden_size).to(x.device),\n",
    "                torch.zeros(batch_size, self.hidden_size).to(x.device),\n",
    "            )\n",
    "        else:\n",
    "            h_t, c_t = initial_states\n",
    "\n",
    "        for state in range(total_cells):\n",
    "            x_t = x[:, state, :]\n",
    "\n",
    "            # Calculate gates\n",
    "            f_t = torch.sigmoid(h_t @ self.U_f + x_t @ self.W_f + self.b_f)\n",
    "            i_t = torch.sigmoid(h_t @ self.U_i + x_t @ self.W_i + self.b_i)\n",
    "            cv_t = torch.tanh(h_t @ self.U_c + x_t @ self.W_c + self.b_c)\n",
    "            c_t = c_t * f_t + i_t * cv_t\n",
    "\n",
    "            # Calculate output gate layer and hidden state\n",
    "            o_t = torch.sigmoid(h_t @ self.U_o + x_t @ self.W_o + self.b_o)\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "            # Add output h_n to the sequence\n",
    "            hidden_sequence.append(h_t.unsqueeze(0))\n",
    "\n",
    "        # Transform hidden sequence\n",
    "        hidden_sequence = torch.cat(hidden_sequence, dim=0)\n",
    "        hidden_sequence = hidden_sequence.transpose(0, 1).contiguous()\n",
    "        return hidden_sequence, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gjeg3rwEHCJp"
   },
   "source": [
    "## 3. Модель\n",
    "\n",
    "В этом задании вам предстоит объединить вашу сеть с несколькими другими слоями для создания итоговой модели классификатора (можно начать с самой базовой архитектуры, слой эмбеддингов - LSTM - выходной слой)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-27T00:02:15.614Z"
    },
    "id": "yqY4UEcsMzky"
   },
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(300, 32)\n",
    "        self.LSTM = LSTM_cell(32, 32)\n",
    "        self.fc = nn.Linear(32, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, (h_n, c_n) = self.LSTM(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGBjcKD8DPL4"
   },
   "source": [
    "## 4. Обучение модели.\n",
    "\n",
    "Обученную модель примените для получения предсказаний на Kaggle. Баллы за задания из ноутбука (максимум 5) ставятся в случае, если модель корректно отработала, и вы смогли успешно отправить посылку на Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vyBBBX75Epud"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "qz-CM0L4CD7j"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=808\n",
    ")\n",
    "\n",
    "X_train, y_train = torch.tensor(X_train), torch.tensor(y_train)\n",
    "X_test, y_test = torch.tensor(X_test), torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "qBKk7fYjDPL4"
   },
   "outputs": [],
   "source": [
    "model_train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    model_train, batch_size=128, shuffle=True\n",
    ")\n",
    "\n",
    "model_test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    model_test, batch_size=128, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "uHbbCA3eEiYu"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "clf = LSTM_model().to(device)\n",
    "optimizer = optim.Adam(clf.parameters(), lr=0.004)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j2I5NG6AGOXq",
    "outputId": "3f022409-ccf0-483e-dc47-7eade520b96f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 62/62 [00:23<00:00,  2.69it/s, accuracy=0.46, epoch=0, loss=1.31]\n",
      "Epoch: 1: 100%|██████████| 62/62 [00:22<00:00,  2.71it/s, accuracy=0.50, epoch=1, loss=1.17]\n",
      "Epoch: 2: 100%|██████████| 62/62 [00:23<00:00,  2.68it/s, accuracy=0.49, epoch=2, loss=1.13]\n",
      "Epoch: 3: 100%|██████████| 62/62 [00:23<00:00,  2.68it/s, accuracy=0.51, epoch=3, loss=1.12]\n",
      "Epoch: 4: 100%|██████████| 62/62 [00:23<00:00,  2.67it/s, accuracy=0.51, epoch=4, loss=1.07]\n",
      "Epoch: 5: 100%|██████████| 62/62 [00:23<00:00,  2.68it/s, accuracy=0.53, epoch=5, loss=1.13]\n",
      "Epoch: 6: 100%|██████████| 62/62 [00:23<00:00,  2.64it/s, accuracy=0.55, epoch=6, loss=0.91]\n",
      "Epoch: 7: 100%|██████████| 62/62 [00:23<00:00,  2.69it/s, accuracy=0.62, epoch=7, loss=0.862]\n",
      "Epoch: 8: 100%|██████████| 62/62 [00:23<00:00,  2.68it/s, accuracy=0.62, epoch=8, loss=0.959]\n",
      "Epoch: 9: 100%|██████████| 62/62 [00:23<00:00,  2.65it/s, accuracy=0.63, epoch=9, loss=0.988]\n",
      "Epoch: 10: 100%|██████████| 62/62 [00:23<00:00,  2.68it/s, accuracy=0.63, epoch=10, loss=0.756]\n",
      "Epoch: 11: 100%|██████████| 62/62 [00:23<00:00,  2.68it/s, accuracy=0.64, epoch=11, loss=0.891]\n",
      "Epoch: 12: 100%|██████████| 62/62 [00:23<00:00,  2.67it/s, accuracy=0.65, epoch=12, loss=0.935]\n",
      "Epoch: 13: 100%|██████████| 62/62 [00:23<00:00,  2.64it/s, accuracy=0.64, epoch=13, loss=0.902]\n",
      "Epoch: 14: 100%|██████████| 62/62 [00:23<00:00,  2.69it/s, accuracy=0.64, epoch=14, loss=0.877]\n",
      "Training: 15it [05:47, 23.18s/it, accuracy=0.64, epoch=14, loss=0.877]\n"
     ]
    }
   ],
   "source": [
    "epoch_bar = tqdm(range(15), desc=\"Training\", position=0, total=2)\n",
    "acc = 0\n",
    "\n",
    "for epoch in epoch_bar:\n",
    "    batch_bar = tqdm(\n",
    "        enumerate(train_loader),\n",
    "        desc=\"Epoch: {}\".format(str(epoch)),\n",
    "        position=0,\n",
    "        total=len(train_loader),\n",
    "    )\n",
    "\n",
    "    for i, (datapoints, labels) in batch_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = clf(datapoints.long().to(device))\n",
    "        loss = criterion(preds, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 50 == 0:\n",
    "            acc = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i, (datapoints_, labels_) in enumerate(test_loader):\n",
    "                    preds = clf(datapoints_.to(device))\n",
    "                    acc += (\n",
    "                        (preds.argmax(dim=1) == labels_.to(device))\n",
    "                        .float()\n",
    "                        .sum()\n",
    "                        .cuda()\n",
    "                        .item()\n",
    "                    )\n",
    "            acc /= len(X_test)\n",
    "\n",
    "        batch_bar.set_postfix(\n",
    "            loss=loss.cuda().item(), accuracy=\"{:.2f}\".format(acc), epoch=epoch\n",
    "        )\n",
    "        batch_bar.update()\n",
    "\n",
    "    epoch_bar.set_postfix(\n",
    "        loss=loss.cuda().item(), accuracy=\"{:.2f}\".format(acc), epoch=epoch\n",
    "    )\n",
    "    epoch_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVIVwu94UOUu",
    "outputId": "b328d511-fdb9-41d5-e521-36191e1a8bfc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_global = torch.tensor(X_global)\n",
    "model_global = torch.utils.data.TensorDataset(X_global)\n",
    "global_loader = torch.utils.data.DataLoader(\n",
    "    model_global, batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nbS-MAwKdfum"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "_yLOyJcDgZ0M"
   },
   "outputs": [],
   "source": [
    "preds = clf(X_global.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "t18vOqwAj7c8"
   },
   "outputs": [],
   "source": [
    "preds = preds.cpu().argmax(dim=1).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "_sMOR3mPesjm"
   },
   "outputs": [],
   "source": [
    "sub_preds = labeling.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "FvMtbbeckUn8"
   },
   "outputs": [],
   "source": [
    "df_test[\"Category\"] = sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "C4p6zgoykguX"
   },
   "outputs": [],
   "source": [
    "submission = df_test[\"Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "Y2Q2a7IUkwQ_"
   },
   "outputs": [],
   "source": [
    "df_test = df_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "oVbZv8TVlG-b"
   },
   "outputs": [],
   "source": [
    "submission = df_test[[\"index\", \"Category\"]]\n",
    "submission.columns = [\"id\", \"Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "-M4xo5N_kpNP"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission1.csv\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24VNfcMWHaKJ"
   },
   "source": [
    "## Система оценивания домашнего задания\n",
    "\n",
    "В домашнем задании две смысловые части:\n",
    "\n",
    "1. выполнение заданий из ноутбука --- **5 баллов**\n",
    "\n",
    "2. создание архитектуры сети, дающей как можно лучшее качество на Kaggle --- **5 баллов (+5 бонусных баллов)**. Эта архитектура не обязана содержать написанный вами собственноручно LSTM слой.\n",
    "\n",
    "\n",
    "#### Оценивание результатов Kaggle:\n",
    "\n",
    "Основные баллы (максимум 5) вычисляются по следующему правилу по public leaderboard:\n",
    "\n",
    "val_accuracy $\\geq$ baseline (0.96367): 1 балл\n",
    "\n",
    "val_accuracy $\\geq$ 0.968: 2 балла\n",
    "\n",
    "val_accuracy $\\geq$ 0.972: 3 балла\n",
    "\n",
    "val_accuracy $\\geq$ 0.976: 4 балла\n",
    "\n",
    "val_accuracy $\\geq$ 0.98: 5 баллов\n",
    "\n",
    "Бонусные баллы:\n",
    "\n",
    "Если вы верно выполнили задание с имплементацией LSTM в этом ноутбуке и попали в топ-3 **среди всех студентов, посещающих курс**, вы получаете бонусные 5 баллов.\n",
    "\n",
    "**Максимальный суммарный балл за домашнее задание** - 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "2Ufl4JUCoS-Y",
    "outputId": "eb25f507-c84b-4345-e7dc-161199897c4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>На полигоне «Погоново» Воронежской области про...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#БудниМЧС #МЧС #МЧСРОССИИ &lt;br&gt;&lt;br&gt;Пожарные тра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Друзья, напоминаем вам, что завтра единый день...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Настольная игра: \"Королевская почта\"&lt;br&gt;&lt;br&gt;По...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Миллиарды писем разносят по почтовым ящикам на...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  На полигоне «Погоново» Воронежской области про...\n",
       "1  #БудниМЧС #МЧС #МЧСРОССИИ <br><br>Пожарные тра...\n",
       "2  Друзья, напоминаем вам, что завтра единый день...\n",
       "3  Настольная игра: \"Королевская почта\"<br><br>По...\n",
       "4  Миллиарды писем разносят по почтовым ящикам на..."
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"./train.csv\")\n",
    "df_train.head()\n",
    "\n",
    "df_test = pd.read_csv(\"./test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FxxGrtK_prP1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UFvbFLkYtLAc"
   },
   "outputs": [],
   "source": [
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AJfriYGTtOuZ"
   },
   "outputs": [],
   "source": [
    "v = TfidfVectorizer(preprocessor=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lpf0ugtXtoOe"
   },
   "outputs": [],
   "source": [
    "df_train[\"text\"] = df_train[\"text\"].fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MgVYgHjSDPL5"
   },
   "outputs": [],
   "source": [
    "v = TfidfVectorizer()\n",
    "v.fit(df_train[\"text\"].values)\n",
    "\n",
    "X = v.transform(df_train[\"text\"].values)\n",
    "X = v.transform(df_train[\"text\"].values)\n",
    "\n",
    "X_global = v.transform(df_test[\"text\"].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NS3goOgEoc-M"
   },
   "outputs": [],
   "source": [
    "labeling = LabelEncoder()\n",
    "y = labeling.fit_transform(df_train[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8DQf-50_of4k"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gT1iUBZKq9za"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "J_2pz_d0t5YB"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=808, stratify=y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "QmQ-GcNJrhpO"
   },
   "outputs": [],
   "source": [
    "xgb_cool3 = xgb.XGBClassifier(colsample_bylevel=1, colsample_bytree=1,\n",
    "       gamma=0, learning_rate=0.18, max_delta_step=0, max_depth=10,\n",
    "       min_child_weight=1, missing=None, n_estimators=140, nthread=-1,\n",
    "       objective='multi:softmax', reg_alpha=0, reg_lambda=3,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ghXyc7Tp4FT",
    "outputId": "aff7570b-c0c2-4744-bb32-47fdb2fabcc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.18, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=-1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0,\n",
       "              silent=True, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cool3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BKH5hN3Q2wsL"
   },
   "outputs": [],
   "source": [
    "for1 = RandomForestClassifier(max_depth=100, n_estimators=32)\n",
    "for2 = RandomForestClassifier(max_depth=None, n_estimators=50)\n",
    "for3 = RandomForestClassifier(max_depth=None, n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ALASvmVht9qv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lee1p2uLuDD-",
    "outputId": "009b8f42-0ea3-46b0-c479-7bd968b705fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9595278246205734"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, xgb_cool3.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DD5nXCUc2Jzn"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Rtob55p82J2D"
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('rf', for2),\n",
    "    ('svr', xgb_cool),\n",
    "    ('svr21', LogisticRegression(C=50, max_iter=1000)),\n",
    "    ('svr2', for3)\n",
    "]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(C=40, max_iter=1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6jryXvg2J4J",
    "outputId": "f554e05f-43d5-4956-d9d1-b8ff3f1e6f18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=None,\n",
       "                   estimators=[('rf',\n",
       "                                RandomForestClassifier(bootstrap=True,\n",
       "                                                       ccp_alpha=0.0,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=None,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       max_samples=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=50,\n",
       "                                                       n_jobs=None,...\n",
       "                                                       random_state=None,\n",
       "                                                       verbose=0,\n",
       "                                                       warm_start=False))],\n",
       "                   final_estimator=LogisticRegression(C=40, class_weight=None,\n",
       "                                                      dual=False,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      intercept_scaling=1,\n",
       "                                                      l1_ratio=None,\n",
       "                                                      max_iter=1000,\n",
       "                                                      multi_class='auto',\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      random_state=None,\n",
       "                                                      solver='lbfgs',\n",
       "                                                      tol=0.0001, verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                   n_jobs=None, passthrough=False, stack_method='auto',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "F6p1DoCtp65b"
   },
   "outputs": [],
   "source": [
    "preds = clf.predict(X_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "XWXLJOY0stN3"
   },
   "outputs": [],
   "source": [
    "sub_preds = labeling.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "FB12G-8-p92O"
   },
   "outputs": [],
   "source": [
    "df_test[\"Category\"] = sub_preds\n",
    "df_test = df_test.reset_index()\n",
    "submission = df_test[[\"index\", \"Category\"]]\n",
    "submission.columns = [\"id\", \"Category\"]\n",
    "submission.to_csv(\"submission13.csv\", index=0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-02-Shirnin.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
